{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset: https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #for data augumentation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog #provides a dialog box to select files.\n",
    "from PIL import Image, ImageTk #ImageTk - Converts images for display in Tkinter GUIs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "train_dir = r\"C:\\Users\\mukund kuthe\\Downloads\\archive\\train\"\n",
    "valid_dir = r\"C:\\Users\\mukund kuthe\\Downloads\\archive\\valid\"\n",
    "test_dir = r\"C:\\Users\\mukund kuthe\\Downloads\\archive\\test\"\n",
    "\n",
    "# Set up ImageDataGenerators for loading images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukund kuthe\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape =(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: wildfire or no wildfire\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukund kuthe\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 477ms/step - accuracy: 0.8733 - loss: 0.2981 - val_accuracy: 0.9365 - val_loss: 0.1576\n",
      "Epoch 2/2\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 360ms/step - accuracy: 0.9304 - loss: 0.1915 - val_accuracy: 0.9483 - val_loss: 0.1383\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save(\"ffd_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog  \n",
    "\n",
    "from PIL import Image, ImageTk  \n",
    "import numpy as np  \n",
    "import tensorflow as tf  \n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model(\"ffd_model.h5\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function to load and predict an image\n",
    "def predict_image():\n",
    "    # Open file dialog to select an image\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Display the image in the GUI\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((200, 200))\n",
    "        img = ImageTk.PhotoImage(img)    #convert image for tk\n",
    "        image_label.configure(image=img) #update the image in GUI\n",
    "        image_label.image = img\n",
    "\n",
    "        # Preprocess the image for the model\n",
    "        img_for_model = Image.open(file_path).resize((64, 64))\n",
    "        img_array = np.array(img_for_model) / 255.0  # Rescale like during training\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Make a prediction\n",
    "        prediction = model.predict(img_array)[0][0] #extracts the scalar prediction value\n",
    "        result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
    "        result_label.config(text=\"Prediction: \" + result)\n",
    "\n",
    "# Setting up the GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Forest Fire Detection\")\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "# Add widgets\n",
    "btn = tk.Button(root, text=\"Upload Image\", command=predict_image) #button triggers the predict_image() function when clicked\n",
    "btn.pack(pady=20)\n",
    "\n",
    "#Placeholder for displaying the selected image\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack()\n",
    "\n",
    "#Label to display the prediction result\n",
    "result_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 16))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "#Starts the Tkinter event loop, keeping the GUI active until manually closed\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2860500,
     "sourceId": 4932759,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
